# üé≠ Deepfake Video Detection
A comprehensive deep learning pipeline to detect deepfake videos using both video and text-based models. This project supports preprocessing, metadata generation, model training, and inference. It also includes support for large datasets using Git LFS and GitHub Codespaces.

## üìå Features
- ‚úÖ Deepfake detection using video and textual metadata
- üß† Pretrained model support (`.pth`, `.safetensors`)
- üé• Video preprocessing and frame extraction
- üìÑ Automatic metadata generation
- üíæ Git LFS support for large files
- üíª GitHub Codespaces ready
- üöÄ Modular, extensible Python codebase

## üßæ Table of Contents
- [Project Structure](#project-structure)
- [Setup Instructions](#setup-instructions)
- [Using Git LFS](#using-git-lfs)
- [Usage Guide](#usage-guide)
- [Running in GitHub Codespaces](#running-in-github-codespaces)
- [Contributing](#contributing)
- [Troubleshooting](#troubleshooting)
- [Acknowledgements](#acknowledgements)

## üóÇÔ∏è Project Structure
Deepfake-Detector-Updated/
‚îú‚îÄ‚îÄ model/ # Trained models and configs
‚îÇ ‚îú‚îÄ‚îÄ model.pth # Model weights (LFS)
‚îÇ ‚îî‚îÄ‚îÄ text_model/
‚îÇ ‚îú‚îÄ‚îÄ config.json
‚îÇ ‚îî‚îÄ‚îÄ model.safetensors # HuggingFace format (LFS)
‚îú‚îÄ‚îÄ videos/ # Raw input videos (LFS)
‚îú‚îÄ‚îÄ preprocessed_videos/ # Frame-by-frame video data
‚îú‚îÄ‚îÄ tokenizer/ # Tokenizer files (optional)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .gitattributes
‚îú‚îÄ‚îÄ metadata.json
‚îú‚îÄ‚îÄ gen_metadata.py # Simple metadata script
‚îú‚îÄ‚îÄ generate_metadata.py # Advanced metadata generation
‚îú‚îÄ‚îÄ model.py # Model architecture
‚îú‚îÄ‚îÄ predict.py # Inference script
‚îú‚îÄ‚îÄ train.py # Training loop
‚îú‚îÄ‚îÄ video_processing.py # Preprocesses videos into frames
‚îî‚îÄ‚îÄ README.md

## ‚öôÔ∏è Setup Instructions

### 1. Clone the Repository (with LFS)
Make sure [Git LFS is installed](https://git-lfs.github.com/):

git lfs install
git clone https://github.com/Yogeshkumar786/Deepfake-Video-Detection.git
cd Deepfake-Video-Detection
git lfs pull
### 2. Set Up a Virtual Environment (Recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
### 3. Install Dependencies
If there's a requirements.txt, run:
pip install -r requirements.txt
Otherwise, install manually:

pip install torch torchvision transformers opencv-python tqdm

## üíæ Using Git LFS
This project uses [Git Large File Storage (LFS)] to manage big files:

Tracked files:
.mp4 ‚Äî input videos

.pth ‚Äî model checkpoints

.safetensors ‚Äî HuggingFace model format

Commands to manage:
git lfs install
git lfs track "*.mp4"
git lfs track "*.pth"
git lfs track "*.safetensors"
git add .gitattributes
To push LFS files:

git add path/to/large_file
git commit -m "Add large file"
git push origin main
## üß™ Usage Guide
### 1. Preprocess Videos
Extracts frames from videos and stores them:
python video_processing.py

### 2. Generate Metadata
python generate_metadata.py
or the simpler version:
python gen_metadata.py

### 3. Train the Model
python train.py
Optional flags can be added to choose model type or dataset.

### 4. Run Inference
python predict.py --input_path videos/MY.mp4
üíª Running in GitHub Codespaces
This project is fully compatible with GitHub Codespaces.

Inside Codespaces:
git lfs pull        # Pull large files
python train.py     # Run training
python predict.py   # Run inference
No special changes required. Just make sure .gitattributes and Git LFS are present.

## üßë‚Äçüíª Contributing
We welcome contributions! Here's how you can help:

Fork the repository.
Create a new branch:
git checkout -b feature-name
Commit your changes and push:

git commit -m "Add new feature"
git push origin feature-name
Submit a Pull Request.

Please follow clean code practices and write meaningful commit messages.

## üõ†Ô∏è Troubleshooting
Problem -> Solution
error: src refspec main does not match any -> Run git branch ‚Äî you're likely on master not main
error: file >100MB -> Track the file using Git LFS
RPC failed: curl 55 -> File too large or unstable connection-split into smaller commits
fatal: Could not read from remote repository -> Check your remote URL with git remote -v and fix with git remote set-url origin ...
LFS files not pulling in Codespaces -> Run git lfs pull inside the Codespace terminal

## üôè Acknowledgements
OpenAI, HuggingFace, and PyTorch communities for foundational tools.
Researchers working on deepfake detection for inspiring this project.
Everyone contributing to fighting misinformation and AI misuse.


## üñ•Ô∏è Running on Local PC
If you prefer to run the project on your local machine, follow these steps:
‚úÖ Prerequisites
Make sure the following are installed:
Python 3.8+

Git
Git LFS
pip (comes with Python)
## üöÄ Steps
Clone the repository and pull LFS files
git lfs install
git clone https://github.com/Yogeshkumar786/Deepfake-Video-Detection.git
cd Deepfake-Video-Detection
git lfs pull
(Optional but Recommended) Create a virtual environment

python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
Install required packages

pip install -r requirements.txt
If requirements.txt is missing, install manually:

pip install torch torchvision transformers opencv-python tqdm
Run preprocessing or training scripts

Example usage:
python video_processing.py              # Preprocess videos into frames
python generate_metadata.py            # Generate metadata
python train.py                        # Train model
python predict.py --input_path MY.mp4  # Run prediction

## üí° Tips
Use a GPU-enabled machine for faster model training and inference.
Make sure large files (.mp4, .pth, .safetensors) are pulled via LFS before running the code.
Avoid placing raw datasets inside the repo folder unless tracked with .gitignore or Git LFS.