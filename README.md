# üé≠ Deepfake Video Detection
A comprehensive deep learning pipeline to detect deepfake videos using both video and text-based models. This project supports preprocessing, metadata generation, model training, and inference. The dataset is hosted on Google Drive.

## üìå Features
- ‚úÖ Deepfake detection using video and textual metadata
- üß† Pretrained model support (`.pth`, `.safetensors`)
- üé• Video preprocessing and frame extraction
- üìÑ Automatic metadata generation
- üíª GitHub Codespaces ready
- üöÄ Modular, extensible Python codebase

## üßæ Table of Contents
- [Project Structure](#project-structure)
- [Setup Instructions](#setup-instructions)
- [Dataset Access](#dataset-access)
- [Usage Guide](#usage-guide)
- [Running in GitHub Codespaces](#running-in-github-codespaces)
- [Contributing](#contributing)
- [Troubleshooting](#troubleshooting)
- [Acknowledgements](#acknowledgements)
- [Running on Local PC](#running-on-local-pc)

## üóÇÔ∏è Project Structure

Deepfake-Detector-Updated/
‚îú‚îÄ‚îÄ model/

‚îÇ   ‚îú‚îÄ‚îÄ model.pth

‚îÇ   ‚îî‚îÄ‚îÄ text_model/

‚îÇ       ‚îú‚îÄ‚îÄ config.json

‚îÇ       ‚îî‚îÄ‚îÄ model.safetensors

‚îú‚îÄ‚îÄ videos/

‚îú‚îÄ‚îÄ preprocessed_videos/

‚îú‚îÄ‚îÄ tokenizer/

‚îú‚îÄ‚îÄ .gitignore

‚îú‚îÄ‚îÄ metadata.json

‚îú‚îÄ‚îÄ gen_metadata.py

‚îú‚îÄ‚îÄ generate_metadata.py

‚îú‚îÄ‚îÄ model.py

‚îú‚îÄ‚îÄ predict.py

‚îú‚îÄ‚îÄ train.py

‚îú‚îÄ‚îÄ video_processing.py

‚îî‚îÄ‚îÄ README.md

## ‚öôÔ∏è Setup Instructions

### 1. Clone the Repository
bash->
git clone https://github.com/Yogeshkumar786/Deepfake-Video-Detection.git
cd Deepfake-Video-Detection

### 2. Install Dependencies
pip install torch torchvision transformers opencv-python tqdm

## üíæ Dataset Access
The dataset (videos, model weights, and other large files) is hosted on Google Drive. Download the dataset from the following link and place the files in the appropriate directories:

https://drive.google.com/drive/folders/18yZ9Qw7lYfoZmXNZirAjxZZYjALS4pq9?usp=sharing

Instructions:

1. Download the dataset folder.
2. Extract the contents.
3. Move .mp4 files to the videos/ directory.
4. Move .pth and .safetensors files to the model/ directory.

## üß™ Usage Guide
1. Preprocess Videos
   Extracts frames from videos and stores them: python video_processing.py
2. Generate Metadata
   python gen_metadata.py
3. Train the Model
   python train.py
4. Run Inference
   python predict.py --input_path videos/MY.mp4

## üíª Running in GitHub Codespaces
This project is fully compatible with GitHub Codespaces.

Inside Codespaces:

1. Download the dataset from the Google Drive link.
2. Place the files in the appropriate directories (videos/, model/).
3. Run scripts as needed:
   python train.py     
   python predict.py

## üôè Acknowledgements
1. OpenAI, HuggingFace, and PyTorch communities for foundational tools.
2. Researchers working on deepfake detection for inspiring this project.
3. Everyone contributing to fighting misinformation and AI misuse.

## üñ•Ô∏è Running on Local PC
### ‚úÖ Prerequisites
Make sure the following are installed:
1. Python 3.8+
2. Git
3. pip (comes with Python)

### üöÄ Steps
1. Clone the repository:
   git clone https://github.com/Yogeshkumar786/Deepfake-Video-Detection.git
   cd Deepfake-Video-Detection
2. Download the dataset from the Google Drive link and place files in videos/ and model/.
3. Install required packages:
pip install torch torchvision transformers opencv-python tqdm
4. Run preprocessing or training scripts:
python video_processing.py
python generate_metadata.py
python train.py
python predict.py --input_path MY.mp4

## üí° Tips
1. Use a GPU-enabled machine for faster model training and inference.
2. Ensure dataset files are correctly placed in videos/ and model/ before running the code.
3. Avoid placing raw datasets inside the repo folder unless tracked with .gitignore.
